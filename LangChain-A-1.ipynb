{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828b1d15",
   "metadata": {},
   "source": [
    "### Basic Usages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d36ad",
   "metadata": {},
   "source": [
    "### LangChains only used on Running/Deployed Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330b09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/e3/38d4c5969d91e8e4f2ada469d82322d8b9f5d218613c4a18c11be2bda648/langchain-0.2.5-py3-none-any.whl (974kB)\n",
      "\u001b[K     |████████████████████████████████| 983kB 6.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/d9/31b1b5415be5201ec1ba34ab04f47a92c69174d7817d70b51693fb60e780/langchain_text_splitters-0.2.1-py3-none-any.whl\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/80/07/2640b30384d96a99e88da7d32ff15adcfb10a552e73a337ef220a70cf941/tenacity-8.4.1-py3-none-any.whl\n",
      "Collecting requests<3,>=2\n",
      "  Using cached https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl\n",
      "Collecting async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\"\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl\n",
      "Collecting pydantic<3,>=1\n",
      "  Using cached https://files.pythonhosted.org/packages/17/ba/1b65c9cbc49e0c7cd1be086c63209e9ad883c2a409be4746c21db4263f41/pydantic-2.7.4-py3-none-any.whl\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/e3/5bbe56629093f6ebb72ab79ddff98d3bed2e5b280bfa0206c3feb76c5eab/langsmith-0.1.80-py3-none-any.whl (125kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 16.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n",
      "  Using cached https://files.pythonhosted.org/packages/6e/6c/3c571ae822117affc6b05dd3672b03495878acde15a662677a0c8ac4f194/SQLAlchemy-2.0.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting PyYAML>=5.3\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/6b/6600ac24725c7388255b2f5add93f91e58a5d7efaf4af244fdbcc11a541b/PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting langchain-core<0.3.0,>=0.2.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5d/e69571aca7876484f29d17349072761837e8d597e5cbe61623748ff81696/langchain_core-0.2.9-py3-none-any.whl (321kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 34.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/85/6166b71dc124cbca726f1d062218a61f2541d7c5192bef8c9b518b787132/aiohttp-3.9.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 40.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2,>=1; python_version < \"3.12\"\n",
      "  Using cached https://files.pythonhosted.org/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/09/d82fe4a34c5f0585f9ea1df090e2a71eb9bb1e469723053e1ee9f57c16f3/charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/11/1e78951465b4a225519b8c3ad29769c49e0d8d157a070f681d5b6d64737f/certifi-2024.6.2-py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/ca/1c/89ffc63a9605b583d5df2be791a27bc1a42b7c32bab68d3c8f2f73a98cd4/urllib3-2.2.2-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/e5/3e/741d8c82801c347547f8a2a06aa57dbb1992be9e948df2ea0eda2c8b79e8/idna-3.7-py3-none-any.whl\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Using cached https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl\n",
      "Collecting pydantic-core==2.18.4\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/99/b40e603637e90265401c5253d738d1cb99152e3ee7d2b9c4ddc0ea51b7b1/pydantic_core-2.18.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/ce/0b7ad45504a7634dc49148a12bd654d7fd9b5e9105a31a2fca4307e7d161/orjson-3.10.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 64.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))))\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/74/498377804f8ebfb1efdfbe33e93cf3b29d77e207e9496f0c10912d5055b4/greenlet-3.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting packaging<25,>=23.2\n",
      "  Using cached https://files.pythonhosted.org/packages/08/aa/cc0199a5f0ad350994d660967a8efb233fe0416e4639146c089643407ce6/packaging-24.1-py3-none-any.whl\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl\n",
      "Collecting yarl<2.0,>=1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/c0/8d9a1c02f217f900f248e0ee31377849f4041aff3d36b71b1f30b4a0fa33/yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (308kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 83.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Using cached https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "# !pip install langchain-community langchain-core\n",
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a686ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d646c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HuggingFaceHub' from 'huggingface_hub' (/packages/Transformers_GPU/7c25e58f-77ec-42b5-8776-4b6530aa9315/3.8/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from langchain.llms import HuggingFaceHub\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceHub\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFaceHub(\n\u001b[1;32m      4\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.9\u001b[39m}\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HuggingFaceHub' from 'huggingface_hub' (/packages/Transformers_GPU/7c25e58f-77ec-42b5-8776-4b6530aa9315/3.8/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "# from langchain.llms import HuggingFaceHub\n",
    "from huggingface_hub import HuggingFaceHub\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    model_kwargs = {'temperature':0.9}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b661655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurent_template = \"\"\"I want you to act as naming consultant for new restaurents.Return a list of restaurent names. Each name should be short, catchy and easy to remember. It should relate to type of restaurent.What are the good names for a resutaurent that is {restaurent_description}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = ['restaurent_description'],\n",
    "    template = restaurent_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Hotel only veg recipes\"\n",
    "print(chain.run(description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c0088",
   "metadata": {},
   "source": [
    "### Few shot Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae175d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\" : \"sad\"},\n",
    "    {\"word\": \"bad\", \"antonym\" : \"good\"},\n",
    "    {\"word\": \"tall\", \"antonym\" : \"small\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e1c4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\",\"antonym\"],\n",
    "    template = example_formatter_template\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix = \"Give the antonym of every input\",\n",
    "    suffix = \"Word: {input} \\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "770d2caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "348978ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "Word: bad\n",
      "Antonym: good\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: small\n",
      "\n",
      "\n",
      "Word: Big \n",
      "Antonym: Small\n",
      "\n",
      "\n",
      "Word: Hot\n",
      "Antonym: Cold\n",
      "\n",
      "Word: Left\n",
      "Antonym: Right\n",
      "\n",
      "Word: Up\n",
      "Antonym: Down\n",
      "\n",
      "Word: Right\n",
      "Antonym: Wrong\n",
      "\n",
      "Word: In\n",
      "Antonym: Out\n",
      "\n",
      "Word: Reach\n",
      "Antonym: Fail\n",
      "\n",
      "Word: Add\n",
      "Antonym: Subtract\n",
      "\n",
      "Word: Open\n",
      "Antonym: Close\n",
      "\n",
      "Word: Normal\n",
      "Antonym: Abnormal\n",
      "\n",
      "Word:\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "print(chain.run(\"Big\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b27101",
   "metadata": {},
   "source": [
    "### Types of Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6badebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generic Chains\n",
    "# 2. Utility Chains\n",
    "# 3. Asynchronous Chains\n",
    "# 4. Sequencial Chains\n",
    "# 5. PAL Chains\n",
    "# 6. SQL Database Chains\n",
    "# 7. Transformation Chains\n",
    "# 8. Bash Chain\n",
    "# 9. Requests Chain\n",
    "# 10. API Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75620f63",
   "metadata": {},
   "source": [
    "##### 1. Generic Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dabd353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"India a country\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "690b5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03a307be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_extraction_prompt = PromptTemplate(\n",
    "    input_variables = [\"text_input\"],\n",
    "    template = \"Extract the key facts out of this tex\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2686092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm,prompt=fact_extraction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cf730a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    res = chain.run(article)\n",
    "    print(res)\n",
    "except IndexError as msg:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8116b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb651834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
