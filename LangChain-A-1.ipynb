{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828b1d15",
   "metadata": {},
   "source": [
    "### Basic Usages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d36ad",
   "metadata": {},
   "source": [
    "### LangChains only used on Running/Deployed Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a330b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain-community langchain-core\n",
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a686ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d646c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    model_kwargs = {'temperature':0.9}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b661655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurent_template = \"\"\"I want you to act as naming consultant for new restaurents.Return a list of restaurent names. Each name should be short, catchy and easy to remember. It should relate to type of restaurent.What are the good names for a resutaurent that is {restaurent_description}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = ['restaurent_description'],\n",
    "    template = restaurent_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Hotel only veg recipes\"\n",
    "print(chain.run(description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c0088",
   "metadata": {},
   "source": [
    "### Few shot Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae175d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\" : \"sad\"},\n",
    "    {\"word\": \"bad\", \"antonym\" : \"good\"},\n",
    "    {\"word\": \"tall\", \"antonym\" : \"small\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e1c4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\",\"antonym\"],\n",
    "    template = example_formatter_template\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix = \"Give the antonym of every input\",\n",
    "    suffix = \"Word: {input} \\nAntonym:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "770d2caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "348978ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "Word: bad\n",
      "Antonym: good\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: small\n",
      "\n",
      "\n",
      "Word: Big \n",
      "Antonym: Small\n",
      "\n",
      "\n",
      "Word: Hot\n",
      "Antonym: Cold\n",
      "\n",
      "Word: Left\n",
      "Antonym: Right\n",
      "\n",
      "Word: Up\n",
      "Antonym: Down\n",
      "\n",
      "Word: Right\n",
      "Antonym: Wrong\n",
      "\n",
      "Word: In\n",
      "Antonym: Out\n",
      "\n",
      "Word: Reach\n",
      "Antonym: Fail\n",
      "\n",
      "Word: Add\n",
      "Antonym: Subtract\n",
      "\n",
      "Word: Open\n",
      "Antonym: Close\n",
      "\n",
      "Word: Normal\n",
      "Antonym: Abnormal\n",
      "\n",
      "Word:\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "print(chain.run(\"Big\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b27101",
   "metadata": {},
   "source": [
    "### Types of Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6badebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generic Chains\n",
    "# 2. Utility Chains\n",
    "# 3. Asynchronous Chains\n",
    "# 4. Sequencial Chains\n",
    "# 5. PAL Chains\n",
    "# 6. SQL Database Chains\n",
    "# 7. Transformation Chains\n",
    "# 8. Bash Chain\n",
    "# 9. Requests Chain\n",
    "# 10. API Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75620f63",
   "metadata": {},
   "source": [
    "##### 1. Generic Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dabd353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"India a country\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "690b5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03a307be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_extraction_prompt = PromptTemplate(\n",
    "    input_variables = [\"text_input\"],\n",
    "    template = \"Extract the key facts out of this tex\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2686092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm,prompt=fact_extraction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cf730a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    res = chain.run(article)\n",
    "    print(res)\n",
    "except IndexError as msg:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8116b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb651834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
